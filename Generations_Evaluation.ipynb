{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generations_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WyD2V5xOLNcb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoCozzi96/DeepComedy/blob/main/Generations_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZXVw91Nhsq"
      },
      "source": [
        "#Generations evaluation\n",
        "\n",
        "This notebook is provided for demostrating how we have read all the log files of all the models, extracted the generated texts for each temperature and evaluated them using the specified metrics. This step took some time (we run it on over 247 texts in almost 4 hours) because evaluating a single canto is sometimes a complex operation (depending on the used metrics). \n",
        "\n",
        "At the end, we generate the file \"*results.csv*\" in which all the scores for each generated canto are stored and accessible in an easy way in other notebooks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNCxsaZvRJko"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY6wa1ufRA0F",
        "outputId": "e8344ecf-1cab-4c36-db49-ffa3c7227303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyphen\n",
        "!pip install nltk --upgrade\n",
        "!pip install tensorflow_datasets # used for student's metrics\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import resource\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyphen\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from nltk.metrics import edit_distance\n",
        "\n",
        "\n",
        "# retrieve our GitHub repository\n",
        "!git clone \"https://github.com/RiccardoCozzi96/DeepComedy\"\n",
        "\n",
        "sys.path.append(\"DeepComedy/tokenizer/\")\n",
        "sys.path.append(\"DeepComedy/metrics/\")\n",
        "sys.path.append(\"DeepComedy/datasets/\")\n",
        "\n",
        "from comedy_tokenizer import ComedyTokenizer\n",
        "from comedy_metrics import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyphen\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/5a/5bc036e01389bc6a6667a932bac3e388de6e7fa5777a6ff50e652f60ec79/Pyphen-0.10.0-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyphen\n",
            "Successfully installed pyphen-0.10.0\n",
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=5c96994f58434c77a509e701e6b0a86302da87cc835d15739e5b209dbaece2ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.24.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.12.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (20.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.3)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (50.3.2)\n",
            "Cloning into 'DeepComedy'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 405 (delta 33), reused 0 (delta 0), pack-reused 345\u001b[K\n",
            "Receiving objects: 100% (405/405), 1.29 MiB | 1.48 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQMDk7lit2ij"
      },
      "source": [
        "path = f\"DeepComedy/generated cantos/\"\n",
        "dict_path = \"DeepComedy/tokenizer/dantes_hyphenation_dictionary.csv\"\n",
        "comedy_filename = \"DeepComedy/datasets/commedia.txt\"\n",
        "results_filename = \"DeepComedy/results.csv\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2WDP2R9L7C4"
      },
      "source": [
        "## Functions definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyD2V5xOLNcb"
      },
      "source": [
        "### Metric functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rGXMvxF3YL7",
        "outputId": "c86a6ba5-6060-434f-f1f6-3604742cf9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"imported from comedy_metrics module on the GitHub repo\"\"\"\n",
        "\n",
        "# TABLE_WIDTH = 100 # constant for printing \"fill\" characters\n",
        "\n",
        "# # returns the texts with no \n",
        "# def extract_only_verses(canto):\n",
        "#   return [line for line in canto if line != \"\\n\" and line != \"\"]\n",
        "\n",
        "\n",
        "# def remove_accents(string):\n",
        "#   string = re.sub(r\"[àá]\", \"a\", string)\n",
        "#   string = re.sub(r\"[èé]\", \"e\", string)\n",
        "#   string = re.sub(r\"[ìí]\", \"i\", string)\n",
        "#   string = re.sub(r\"[òó]\", \"o\", string)\n",
        "#   string = re.sub(r\"[ùú]\", \"u\", string)\n",
        "#   return string\n",
        "\n",
        "\n",
        "# def extract_vocabulary(text):\n",
        "#   if type(text) == list:\n",
        "#     s = set()\n",
        "#     for string in text:\n",
        "#       s = s.union(extract_vocabulary(string))\n",
        "#     vocab = s\n",
        "#     return vocab\n",
        "#   else: \n",
        "#     vocab = text.lower()\n",
        "#     vocab = remove_accents(vocab)\n",
        "#     vocab = text.replace(\"\\n\", \" \") \n",
        "#     vocab = re.sub(r\"[^a-z\\s]\", \" \", vocab)\n",
        "#     all_words = vocab.split(\" \")\n",
        "#     unique_words = np.unique(all_words)\n",
        "#     vocab = set([r for r in unique_words if len(r) > 2 ])\n",
        "#     return vocab\n",
        "\n",
        "\n",
        "# def count_verses(canto):\n",
        "#   return len(extract_only_verses(canto))\n",
        "\n",
        "\n",
        "# def evaluate_structure(canto, final_single_verse=True, verbose=False):\n",
        "#   \"\"\"\n",
        "#   canto :\\n\\tlist of strings, each one representing a verse \\n\n",
        "#   final_single_verse (default=True):\\n\\tif False, return the maximum score (1.0) iff all the tercets have 3 verses. \\n\n",
        "#   Otherwise, the maximum score is reached iff the canto ends with a single verse \\n\n",
        "#   verbose (default=False): \\n\\tif True, prints out the count of verses, groups and tercets for each verse \\n\n",
        "#   Return\\n\\tstructuredness score in [0, 1]\n",
        "#   \"\"\"\n",
        "#   groups = 1\n",
        "#   tercets = 0\n",
        "#   verse_counter = 0\n",
        "#   if verbose: \n",
        "#     print(\"{:>40}\\t{:<10}  {:<10}  {:<15}\".format(\"\", \"n. verse\", \"n. groups\", \"n. tercets\"))\n",
        "#     print(\"-\"*TABLE_WIDTH)\n",
        "\n",
        "#   # count groups of verces\n",
        "#   for i, verse in enumerate(canto):\n",
        "#     verse = verse.replace(\"\\n\", \"\")\n",
        "#     if not bool(re.search(\"[a-zA-z]\", verse)):\n",
        "#       groups += 1\n",
        "#       if verse_counter == 3:\n",
        "#         tercets += 1\n",
        "#       verse_counter = 0\n",
        "#     else:\n",
        "#       verse_counter += 1 \n",
        "\n",
        "#     # count the final group which is ignored\n",
        "#     if i == len(canto)-1 and verse_counter == 3:\n",
        "#       tercets += 1\n",
        "\n",
        "#     if verbose: print(\"-{:<40}\\t{:<10}  {:<10}  {:<15}\".format(verse, verse_counter, groups, tercets))\n",
        "\n",
        "#   # check whether the final verse is in a single line\n",
        "#   if final_single_verse:\n",
        "#     correct = (not bool(re.search(\"[a-zA-z]\", canto[-2])) and bool(re.search(\"[a-zA-z]\", canto[-1])))\n",
        "#     if correct:\n",
        "#       tercets += 1\n",
        "#     else: \n",
        "#       groups += 1\n",
        "#       # print(\"ultimo: [{}]\".format(canto[-1]))\n",
        "#       # print(\"penultimo: [{}]\".format(canto[-2]))\n",
        "#     if verbose: \n",
        "#       print(\" \"*40 + \" \")\n",
        "#       print(\"\\t  single final verse:   {}\\t\\t{:<10}  {:<10}  {:<15}\".format(correct, \n",
        "#                                                                             verse_counter, \n",
        "#                                                                             groups, \n",
        "#                                                                             tercets))  \n",
        "#   if verbose: print(\"-\"*TABLE_WIDTH) \n",
        "\n",
        "#   return tercets / groups\n",
        "\n",
        "\n",
        "\n",
        "# # count number of hendecasyllables verses\n",
        "# def evaluate_hendecasyllables(canto, tokenizer, return_count=False, tolerance=1, verbose=False):\n",
        "#     verses = [line for line in canto if line != \"\\n\" and line != \"\"]\n",
        "        \n",
        "#     n_syllables = []\n",
        "#     for verse in [v for v in verses if v != \"\"]:\n",
        "#         verse = verse.replace(\"\\n\", \"\")\n",
        "#         if verse != \"\":\n",
        "#             verse = tokenizer.remove_punctuation(verse)\n",
        "#             sill, n = tokenizer.tokenize_phrase(verse, count_syllables=True)\n",
        "#             if verbose: print(\"{:40}{:80} ({})\".format(verse, sill, n))\n",
        "#             n_syllables.append(n)\n",
        "    \n",
        "#     n_hendecasillables = len([n for n in n_syllables if n in range(11-tolerance, 11+tolerance+1)])\n",
        "    \n",
        "#     if verbose: \n",
        "#         print(\"=\"*80)\n",
        "\n",
        "#     if return_count:\n",
        "#         return n_hendecasillables/len(verses), n_syllables\n",
        "#     else:\n",
        "#         return n_hendecasillables/len(verses)\n",
        "\n",
        "\n",
        "\n",
        "# def average_hendecasyllables(canto, tokenizer, tolerance):\n",
        "#   _, n_syllables = evaluate_hendecasyllables(canto=canto, tokenizer=tokenizer, tolerance=tolerance, return_count=True)\n",
        "#   return np.average(n_syllables)\n",
        "\n",
        "\n",
        "\n",
        "# def avg_rhyming_score(canto, tokenizer, return_n_rhymes=False, raw=True, verbose=False):\n",
        "#   if raw:\n",
        "#     finals = []\n",
        "#     verses = extract_only_verses(canto)\n",
        "#     for verse in verses:\n",
        "#       finals.append(tokenizer.tokenize_phrase(tokenizer.remove_punctuation(verse)).split(\" \")[-2])\n",
        "    \n",
        "#     # find chained rhyme pattern\n",
        "#     scores = []\n",
        "#     for i in range(0, len(verses)-4, 3):\n",
        "#       score = 0\n",
        "#       if finals[i] == finals[i+2]:\n",
        "#         score += 0.5\n",
        "#       if finals[i+1] == finals[i+3]:\n",
        "#         score += 0.5\n",
        "#       scores.append(score)\n",
        "#       if verbose and score != 1: print(\"\\n{:50} ({})\\n{:50} ({})\\n{:50} ({})\\n{:50} ({})\\n- score: {}\".format(\n",
        "#           verses[i], finals[i], verses[i+1], finals[i+1], \n",
        "#           verses[i+2], finals[i+2], verses[i+3], finals[i+3],\n",
        "#           score\n",
        "#       ))\n",
        "\n",
        "\n",
        "#     if return_n_rhymes:\n",
        "#       return np.average(scores), len([s for s in scores if s == 1])\n",
        "#     else:\n",
        "#       return np.average(scores)\n",
        "\n",
        "#   else:\n",
        "#     return None\n",
        "\n",
        "\n",
        "# def ngrams_plagiarism(generated_text, original_text, n=4):\n",
        "#   \"\"\"\n",
        "#   (credits: Luga Giuliani)\n",
        "#   \"\"\"\n",
        "#   return -1\n",
        "#   # the tokenizer is used to remove non-alphanumeric symbols\n",
        "#   tokenizer = tfds.features.text.Tokenizer()\n",
        "#   original_text = tokenizer.join(tokenizer.tokenize(original_text.lower()))\n",
        "#   generated_text_tokens = tokenizer.tokenize(generated_text.lower())\n",
        "\n",
        "#   total_ngrams = len(generated_text_tokens) - n + 1\n",
        "#   plagiarism_counter = 0\n",
        "\n",
        "#   for i in range(total_ngrams):\n",
        "#       ngram = tokenizer.join(generated_text_tokens[i:i+n])\n",
        "#       plagiarism_counter += 1 if ngram in original_text else 0\n",
        "#   return 1 - (plagiarism_counter / total_ngrams)\n",
        "\n",
        "\n",
        "# def find_similar_words(word:str, vocabulary:set, verbose=False, return_best_distance=False):\n",
        "#   \"\"\"\n",
        "#   Given a word, find the most similar words in the vocabulary. \\n\n",
        "#   The similarity between words is computed by the 'edit (Levenshtein) distance'. \\n\n",
        "#   If more than one word from the vocabulary has a same distance from the requested word, \\n\n",
        "#   then a list containing them is returned. \\n\n",
        "#   If #return_best_distance is True, then returns a tuple containing the best words and the best distance. \n",
        "#   \"\"\"\n",
        "#   if verbose: print(f\"looking for words similar to '{word}'\")\n",
        "#   # try normal search\n",
        "#   if word in vocabulary:\n",
        "#     if verbose: print(f\"\\t{(real_word, 0)} <-- match\")\n",
        "#     return ([word], 0) if return_best_distance else [word]\n",
        "\n",
        "#   else:\n",
        "#     most_similar = []\n",
        "#     best_distance = len(word) # the distance between a word and an empty word is equal to the lenght of the word itself\n",
        "\n",
        "#     for real_word in vocabulary:\n",
        "#       dist = word_distance(word, real_word)\n",
        "#       if dist <= best_distance:\n",
        "#         if verbose: print(f\"\\t {real_word} ({dist})\")\n",
        "#         if dist < best_distance:\n",
        "#           best_distance = dist\n",
        "#           most_similar = []\n",
        "#         most_similar.append(real_word)\n",
        "#     return (most_similar, best_distance) if return_best_distance else most_similar\n",
        "\n",
        "\n",
        "# def word_distance(a, b):\n",
        "#   from nltk.metrics import edit_distance\n",
        "#   d = edit_distance(a, b)\n",
        "#   return d\n",
        "\n",
        "\n",
        "\n",
        "# def incorrectness(words:set, real_words:set, verbose=False, return_match_ratio=False, plot_frequencies=False):\n",
        "#   \"\"\"\n",
        "#   Measures the amount of incorrect words, with respect to the given set of real words. \n",
        "#   If all the passed words exists in the real words set, then the returned value is 0, otherwise return a positive real number.\n",
        "#   The score is computed as a weighted average of the frequencies of the distances of the words from the real words. \n",
        "#   A set of words each of which has the nearest word (in Levenshtein distance) at 1 or 2 is way better of another one\n",
        "#   whose nearest word is 10 points far from the most similar real word. \n",
        "#   \"\"\"\n",
        "#   if verbose: print(\"{}\\n{:3}\\t{:10}\\t{:5}\\t{}\\n{}\\n\".format(\"=\"*40, \"%\", \"WORD\", \"DIST\", \"SIMILAR TO\", \"=\"*40))\n",
        "#   n_real_words = len(words)\n",
        "#   # compute frequencies\n",
        "#   distances = []\n",
        "#   for i, my_word in enumerate(words):\n",
        "#     most_similar, distance = find_similar_words(word=my_word, \n",
        "#                                                  vocabulary=real_words,\n",
        "#                                                  return_best_distance=True)\n",
        "#     distances.append(distance)\n",
        "    \n",
        "#   # compute frequencies\n",
        "#   frequencies = dict(zip(np.unique(distances), [distances.count(d) for d in np.unique(distances)]))\n",
        "  \n",
        "#   # add the zero-frequency if not present (in order to compute the correct words percentage)\n",
        "#   if 0 not in frequencies.keys(): frequencies[0] = 0\n",
        "  \n",
        "#   if verbose: print(\"\\n{}\\n frequencies: {}\".format(\"-\"*40, dict(frequencies)))\n",
        "  \n",
        "#   # computing correctness\n",
        "#   incorrectness = round(np.average(np.unique(distances),\n",
        "#                                  weights=[distances.count(d) for\n",
        "#                                           d in np.unique(distances)]), 2)\n",
        "  \n",
        "#   # percentage of incorrect words\n",
        "#   ratio = 1 - round(frequencies[0] / len(words), 2)\n",
        "\n",
        "#   # print final results\n",
        "#   if verbose: \n",
        "#     print(\" match ratio:  {} %\\t({} / {}) \\n{}\".format(ratio, frequencies[0],\n",
        "#                                                        len(words), \"=\"*40))\n",
        "#     if distance != 0: \n",
        "#       print(\"{:>3}\\t{:15}\\t{:<5}\\t{}\".format(round(i/n_real_words*100, 1),\n",
        "#                                              my_word, distance, most_similar))  \n",
        "#   # plot\n",
        "#   if plot_frequencies: \n",
        "#     from matplotlib import pyplot as pyplot\n",
        "#     plt.bar(list(frequencies), [frequencies[key] for key in list(frequencies)])\n",
        "#     plt.show()\n",
        "\n",
        "#   return (incorrectness, ratio) if return_match_ratio else incorrectness\n",
        "\n",
        "# ############################################\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'imported from comedy_metrics module on the GitHub repo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxsG7qL_chsP"
      },
      "source": [
        "### Functions for evaluation and printing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHMKLyldce28"
      },
      "source": [
        "def evaluate(canto, tokenizer, original_text_filename=None, verbose=False):\n",
        "  \n",
        "  # clean text\n",
        "  canto = [verse.lower().replace(\"\\n\", \"\") for verse in canto]  # delete all the \"\\n\"\n",
        "  if canto[0] == \"\": canto = canto[1:]                          # delete the first line if it is empty\n",
        "  if canto[-1] == \"\": canto = canto[:-1]                        # delete the last line if it is empty\n",
        "  \n",
        "  # compute scores\n",
        "  verses_number = count_verses(canto)\n",
        "  structure_score = round(evaluate_structure(canto, final_single_verse=True, verbose=verbose), 3)\n",
        "  hendecasyllables_score = round(evaluate_hendecasyllables(canto, tokenizer, tolerance=1, verbose=verbose), 3)\n",
        "  mean_syllables = round(1 - abs(11 - average_hendecasyllables(canto, tokenizer, tolerance=1)), 2)\n",
        "  rhymeness_score = round(avg_rhyming_score(canto, tokenizer, verbose=verbose), 3)\n",
        "  if original_text_filename != None:\n",
        "    original_text = open(original_text_filename).read()\n",
        "    incorrectness_score = round(incorrectness(extract_vocabulary(canto), extract_vocabulary(original_text)), 3)\n",
        "    plagiarism_score = round(ngrams_plagiarism(''.join(canto), original_text), 3)\n",
        "\n",
        "  return (verses_number, structure_score, hendecasyllables_score, \n",
        "          mean_syllables, rhymeness_score, incorrectness_score, plagiarism_score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_cantos(list_of_cantos, tokenizer, original_text_filename=None, verbose=False):\n",
        "  if len(np.shape(list_of_cantos)) == 1 and type(list_of_cantos[0]) == str:\n",
        "    list_of_cantos = [list_of_cantos]     # transform the single canto passed into a list of 1 canto\n",
        "  elif len(np.shape(list_of_cantos)) > 2:\n",
        "    raise Exception((\"\\nlist_of_cantos can only be:\" + \n",
        "                     \"\\n - a single canto as a list of strings: shape (n,)\" + \n",
        "                     \"\\n - a list of cantos as a list of lists of strings: shape (1, n)\" +\n",
        "                     f\"\\n\\nlist_of_cantos passed has shape {np.shape(list_of_cantos)}\"))\n",
        "\n",
        "  results = {\n",
        "      \"n_vers\": [],\n",
        "      \"struct\": [],\n",
        "      \"hendec\": [],\n",
        "      \"avg_syl\": [],\n",
        "      \"rhymes\": [],\n",
        "      \"incorr\": [],\n",
        "      \"plagiar\": []\n",
        "   }\n",
        "\n",
        "  for i,canto in enumerate(list_of_cantos):\n",
        "    print(f\"Evaluating canto {i+1} of {len(list_of_cantos)}...\", end=\"\")\n",
        "    (verses_number, structure_score, hendecasyllables_score, \n",
        "    mean_syllables, rhymeness_score, incorrectness_score, \n",
        "    plagiarism_score) = evaluate(canto,\n",
        "                                 tokenizer, \n",
        "                                 original_text_filename,\n",
        "                                 verbose)\n",
        "    print(\"done.\")\n",
        "    results[\"n_vers\"].append(verses_number)\n",
        "    results[\"struct\"].append(structure_score)\n",
        "    results[\"hendec\"].append(hendecasyllables_score)\n",
        "    results[\"avg_syl\"].append(mean_syllables)\n",
        "    results[\"rhymes\"].append(rhymeness_score)\n",
        "    results[\"incorr\"].append(-incorrectness_score) # save the negative incorrectness score to have the best score as the highest value\n",
        "    results[\"plagiar\"].append(plagiarism_score)\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "\n",
        "def print_results_table(results, names):\n",
        "\n",
        "  print(\"{}\\n{:^100}\\n{}\".format(\"=\"*TABLE_WIDTH, \"BEST SCORES\", \"=\"*TABLE_WIDTH))\n",
        "  col_width = int(80 / len(list(results)))+1\n",
        "  cell = \"{:<\" + str(col_width) + \"}\"\n",
        "\n",
        "  # rows: metrics,   columns: cantos\n",
        "  if len(names) <= 3:\n",
        "\n",
        "    print(\"{:<20}\".format(\"METRIC\"), end=\"\")\n",
        "\n",
        "    for name in names:\n",
        "      print(cell.format(name), end=\"\")\n",
        "    print(\"\\n\" + \"-\"*TABLE_WIDTH)\n",
        "\n",
        "    for key in results.keys():\n",
        "      print(\"{:<20}\".format(key), end=\"\")\n",
        "      for value in results[key]:\n",
        "        print(cell.format(f\"[ {value} ]\" if (value == max(results[key])) else\n",
        "                          value), end=\"\")\n",
        "      print()\n",
        "    print(\"\\n{}\".format(\"=\"*TABLE_WIDTH))\n",
        "\n",
        "\n",
        "  # rows: cantos,   columns: metrics\n",
        "  else:\n",
        "    print(\"{:40}\".format(\"CANTO\"), end=\"\")              # heading \"canto\"\n",
        "\n",
        "    for colname in list(results):                       # headings of other metrics\n",
        "      print(cell.format(colname), end=\"\")\n",
        "    print(\"\\n\" + \"-\"*TABLE_WIDTH)\n",
        "\n",
        "    for i in range(len(names)):\n",
        "      print(\"{:40}\".format(names[i]), end=\"\")\n",
        "      for key in list(results):\n",
        "        value = results[key][i]\n",
        "        print(cell.format(f\"[ {value} ]\" if value == max(results[key]) else\n",
        "                          value), end=\"\")\n",
        "      print()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb_ruF22MBrq"
      },
      "source": [
        "### Functions for reading and exporting files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JomarYPLMGfd"
      },
      "source": [
        "def read_files(dir, format=\"json\"):                                                                                                  \n",
        "  logs_list = []\n",
        "  logs_names = []     \n",
        "  logs = {}                                                                                              \n",
        "  subdirs = [x[0] for x in os.walk(dir)]                                                                            \n",
        "  for subdir in subdirs:                                                                                            \n",
        "    files = os.walk(subdir).__next__()[2]                                                                             \n",
        "    if (len(files) > 0):                                                                                          \n",
        "      for file in files:        \n",
        "        if file.endswith(f\".{format}\"):\n",
        "          with open(os.path.join(subdir, file), 'r') as fp:\n",
        "            logs[file] = json.load(fp)                                                              \n",
        "  return logs\n",
        "\n",
        "\n",
        "def save_as_dataframe(dictionary, file_name):\n",
        "  import pandas as pd\n",
        "  df = pd.DataFrame()\n",
        "  info = np.array([g.split(\"/\") for g in generations_names])\n",
        "  df[\"model\"] = [m.replace(\"LOG_\", \"\") for m in info[:, 0]]\n",
        "  df[\"temperature\"] = [float(m.replace(\"temp_\", \"\")) for m in info[:, 1]]\n",
        "  for key in dictionary.keys():\n",
        "    df[key] = dictionary[key]\n",
        "  df.to_csv(file_name)\n",
        "  print(\"\\n\\n--------------------\\nsaved as\", file_name)\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvx9jz6tRlTf"
      },
      "source": [
        "## Load files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOeNisl7Wm_L",
        "outputId": "cc33b93c-e8dc-4cd4-b283-8c98ff3493e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "logs = read_files(path)\n",
        "print(len(logs), \"log files.\\n\")\n",
        "for l in logs:\n",
        "  print(l)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22 log files.\n",
            "\n",
            "LOG_1_7_256_512_4_0_150.json\n",
            "LOG_7_1_256_512_4_0_150.json\n",
            "LOG_5_5_256_512_4_150_150.json\n",
            "LOG_7_5_256_512_4_0_150.json\n",
            "LOG_1_5_256_512_4_0_150.json\n",
            "LOG_1_1_256_512_4_0_150.json\n",
            "LOG_1_3_256_512_4_0_150.json\n",
            "LOG_5_7_256_512_4_0_150.json\n",
            "LOG_5_3_256_512_4_150_150.json\n",
            "LOG_5_5_256_512_4_0_70.json\n",
            "LOG_5_3_256_512_4_70_70.json\n",
            "LOG_5_1_256_512_4_0_150.json\n",
            "LOG_6_6_256_512_4_0_70.json\n",
            "LOG_5_5_256_512_4_70_70.json\n",
            "LOG_5_5_256_512_4_0_150.json\n",
            "LOG_3_1_256_512_4_0_150.json\n",
            "LOG_6_6_256_512_4_0_150.json\n",
            "LOG_5_3_256_512_4_0_150.json\n",
            "LOG_3_3_256_512_4_0_150.json\n",
            "LOG_7_3_256_512_4_0_150.json\n",
            "LOG_3_3_256_512_4_150_150.json\n",
            "LOG_7_7_256_512_4_0_150.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSJiMItWYDoN",
        "outputId": "e9205a67-da1f-4414-b76b-960d82fccd5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "generations = []\n",
        "generations_names = []\n",
        "for log in logs:\n",
        "  for temp in logs[log]['generations']:\n",
        "    gen = log.replace('.json', '/')+temp\n",
        "    generations.append(logs[log]['generations'][temp].replace(' ,',',').replace(' .','.').replace(' !','!').replace(' ?','?').replace(' :',':').replace(' ;',';').split('\\n'))\n",
        "    generations_names.append(gen)\n",
        "\n",
        "print(len(generations_names), \"cantos\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "242 cantos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUwxVcEI0KAb"
      },
      "source": [
        "## Evaluation of cantos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4evf7k5gHbw"
      },
      "source": [
        "### Load the hyphenation dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDXjvEh5gFdE",
        "outputId": "53ccb29b-4cb1-44f4-908b-8272bbf2abcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dante_tokenizer = ComedyTokenizer.from_dataframe(pd.read_csv(dict_path,\n",
        "                                                             index_col=\"word\"),\n",
        "                                           synalepha=True,\n",
        "                                           use_tercets=True)\n",
        "\n",
        "print(\"tokenizer loaded.\\nhyphenation test:\\t\", dante_tokenizer.tokenize_phrase(\"una selva oscura\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer loaded.\n",
            "hyphenation test:\t <V> ù na <S> sél va~o scu ra </V>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhzvB_xeQOqa"
      },
      "source": [
        "## Evaluating generated cantos from log file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk2bdwOtp2Qq"
      },
      "source": [
        "Run this cell to evaluate all the canots. \n",
        "(**NOTE**: it can be take one minute for each canto)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlUKwZGcpxiT"
      },
      "source": [
        "# # compute the results among all the generated cantos in the log\n",
        "# print(f\"Evaluating {len(generations)} cantos...\")\n",
        "# results = evaluate_cantos(list_of_cantos=generations, \n",
        "#                           tokenizer=dante_tokenizer, \n",
        "#                           original_text_filename=comedy_filename,\n",
        "#                           verbose=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1B7FpAl1NYn"
      },
      "source": [
        "# save_as_dataframe(results, \"test.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-nQeZzVqfwc",
        "outputId": "ce149efc-1fcc-42e4-963d-f38e0e6bc767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# load results as .csv file as pandas dataframe\n",
        "df_results = pd.read_csv(results_filename, index_col=0)\n",
        "df_results.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>temperature</th>\n",
              "      <th>n_vers</th>\n",
              "      <th>struct</th>\n",
              "      <th>hendec</th>\n",
              "      <th>avg_syl</th>\n",
              "      <th>rhymes</th>\n",
              "      <th>incorr</th>\n",
              "      <th>plagiar</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_1_256_512_4_0_150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.891</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_1_256_512_4_0_150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.891</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_1_256_512_4_0_150</td>\n",
              "      <td>0.7</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.875</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_1_256_512_4_0_150</td>\n",
              "      <td>0.8</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.828</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_1_256_512_4_0_150</td>\n",
              "      <td>0.9</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.891</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  model  temperature  n_vers  ...  rhymes  incorr  plagiar\n",
              "id                                            ...                         \n",
              "0   1_1_256_512_4_0_150          0.5     100  ...   0.891   -0.44       -1\n",
              "1   1_1_256_512_4_0_150          0.6     100  ...   0.891   -0.43       -1\n",
              "2   1_1_256_512_4_0_150          0.7     100  ...   0.875   -0.45       -1\n",
              "3   1_1_256_512_4_0_150          0.8     100  ...   0.828   -0.32       -1\n",
              "4   1_1_256_512_4_0_150          0.9     100  ...   0.891   -0.51       -1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}