# DeepComedy: Generating cantos in the style of the Divine Comedy by Dante Alighieri. 

The artificial generation of poetries has been proposed several times as a way
to demonstrate the performance of sequence-to-sequence models such as RNNs and
LSTMs used in transfer learning tasks oriented to capture the intrinsic characteristics of a
set of textual documents and producing a novel text with the same style. The standard
solutions proposed so far copied the writing styles and the structure of the text but in some
cases it is too difficult to catch some more hidden and complex characteristics, like rhymes,
and keep the references to the context for a long period. With this work we want to
demonstrate how good transformers are in performing those tasks, even on the relatively
small dataset of the Divine Comedy, by reproducing the Dante’s style of writing and
vocabulary, in some case imitating the Tuscan involved language, by building new
nonexistent but convincing words in a sort of metasemantic poems, perfectly respecting the
rules of terza rima and hendecasyllables, without any type of external heuristic
intervention.

A quick demo of our results:

*E io vidi con le genti in novelle*

*più alto poco dir per la vista corte*

*rivolge a la cagion che non favelle.*


*ma dimmi quei che pace a te forte,*


*se troppa luce, che la gente nota,*

*rimembrar dal fatto hai mano inforte!.*


*ed ella: io di onde qui rinota,*

*rispuos'io lui, ti giova prìa ch'i' tolsi*

*come mano a costui fu sì commota.*
